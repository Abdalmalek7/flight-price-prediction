# src/inference.py
"""
INFERENCE MODULE

This module handles all steps required to make predictions using the trained ML model.
It includes functions to:
1. Load the trained model from disk
2. Load the preprocessing pipeline
3. Transform raw user input using the same preprocessing as in training
4. Run predictions on processed features

Used by:
    app/streamlit_app.py
"""

import os
import joblib
import pandas as pd
import sys

# Add project root to sys.path so imports work when running scripts directly
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# Import pipeline path from data_pipeline
from src.data_pipeline import PIPELINE_PATH

# Path to the saved trained model
MODEL_PATH = os.path.join("models", "success_model.pkl")


def load_trained_model(model_path: str = MODEL_PATH):
    """
    Load the trained XGBoost model from disk.

    Args:
        model_path (str): Path to the saved trained model file.

    Returns:
        model: Loaded trained model ready for inference.

    Raises:
        FileNotFoundError: If the model file does not exist.
    """
    if not os.path.exists(model_path):
        raise FileNotFoundError(
            f"Model file not found at {model_path}. "
            f"Did you run the training pipeline first?"
        )

    # Load model from file
    model = joblib.load(model_path)
    return model


def load_pipeline(pipeline_path: str = PIPELINE_PATH):
    """
    Load the preprocessing pipeline used during training.

    Args:
        pipeline_path (str): Path to the saved pipeline file.

    Returns:
        pipe: Preprocessing pipeline for transforming raw inputs.

    Raises:
        FileNotFoundError: If the pipeline file does not exist.
    """
    if not os.path.exists(pipeline_path):
        raise FileNotFoundError(
            f"Pipeline file not found at {pipeline_path}. "
            f"Did you run the training pipeline first?"
        )

    # Load preprocessing pipeline from file
    pipe = joblib.load(pipeline_path)
    return pipe


def prepare_features_from_raw(raw_df: pd.DataFrame) -> pd.DataFrame:
    """
    Apply preprocessing to raw user input data.

    This function uses the same transformations as applied during training,
    ensuring the input features match the model's expected format.

    Args:
        raw_df (pd.DataFrame): Raw input data from user.

    Returns:
        pd.DataFrame: Preprocessed features ready for prediction.
    """
    # Load the saved pipeline
    features = load_pipeline().transform(raw_df)
    return features


def predict_from_raw(model, raw_df: pd.DataFrame):
    """
    Run full inference pipeline: preprocess input and make predictions.

    Steps:
        1. Preprocess raw input features
        2. Predict target using the trained model

    Args:
        model: Trained ML model.
        raw_df (pd.DataFrame): Raw user input features.

    Returns:
        np.ndarray: Predictions generated by the model.
    """
    # Preprocess raw input
    features = prepare_features_from_raw(raw_df)

    # Make predictions using the trained model
    preds = model.predict(features)
    return preds
